[toc]

## 一、Redis 持久化

### 1. 为什么要持久化

Redis 持久化的目的并不是存储数据，而是**在服务器宕机后（保存在内存中的数据消失），可以重启从磁盘文件中快速恢复数据。**



![image-20211220234025727](images/image-20211220234025727.png)

Redis 提供了两种持久化的方式，分别时RDB 和 AOF，通过 `info `命令可以查看关于持久化的信息：

![image-20211227224740395](images/image-20211227224740395.png)





### 2. RDB

RDB（Redis Database）是 Redis **默认的持久化存储方式**，实现方式是**生成某一刻的二进制快照文件**，所以当Redis宕机重启后，可能会丢失一些数据

#### 2.1 RDB触发快照方式

- 配置 `redis.conf` RDB快照生成规则

  ```sh
  save "" # 不使用RDB存储 不能主从
  
  save 900 1 # 表示15分钟（900秒钟）内至少1个键被更改则进行快照。
  save 300 10 # 表示5分钟（300秒）内至少10个键被更改则进行快照。
  save 60 10000 # 表示1分钟内至少10000个键被更改则进行快照。
  ```

  ![image-20220105165628108](images/image-20220105165628108.png)

- 手动执行 **`bgsave `**命令

  ```sh
  127.0.0.1:6379> bgsave 
  Background saving started
  ```

- 手动执行 **`flushall`** 命令

- 第一次执行主从复制操作

#### 2.2 RDB 原理

![image-20211220235809271](images/image-20211220235809271.png)

1. 主进程收到生成快照的指令后，首先判断是否已有其他子进程在执行RDB操作，是的话则结束当前任务（如：bgsave命令直接返回）
2. 主进程调用 OS 的 fork函数创建一个子进程（复制主进程的所有操作和数据），此过程需要阻塞主进程
3. 主进程 fork 完成，`bgsave `命令返回 `”Background saving started”` 信息并不再阻塞父进程，并可以响应其他命令
4. 子进程利用内存快照中的数据，生成临时的RDB文件，当临时文件完全生成后替换原来的RDB文件
5. 子进程发送信号给主进程表示完成，父进程更新统计信息

#### 2.3 RDB文件

RDB文件存储再 **dump.rdb** 中，其文件如下

![image-20220105171146227](images/image-20220105171146227.png)

可以用 **winhex** 打开 **dump.rdb**文件查看

![image-20220105171236021](images/image-20220105171236021.png)

#### 2.4 RDB的优缺点

**优点**

- RDB文件是二进制的压缩文件，占用空间小且便于传输（主从复制）
- 主进程fork子进程，通过子进程生成新的RDB文件，减少了主进程的阻塞时间

**缺点**

- 由于RDB是一种快照文件，根据触发规则重新生成快照，无法做到实时的数据持久化，所以存在数据不一致（主从复制）及重启丢失数据（根据默认快照配置，可能存在15min的数据丢失）的情况

- 当主进程的资源很大时（内存数据），fork过程将导致主进程长时间阻塞





### 3. AOF

AOF（append only file）也是Redis持久化方式之一，默认不开启。

开启AOF持久化后，Redis 将所有**写操作的命令及参数（RESP）记录到 AOF 文件**，以此达到记录数据库状态的目的。当Redis宕机重启后，只需按顺序重新执行AOF中的命令即可恢复数据

#### 3.1 开启 AOF 配置

配置 `redis.conf` AOF开启

```sh
# 可以通过修改redis.conf配置文件中的appendonly参数开启 
appendonly yes 

# AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的。 
dir ./ 

# 默认的文件名是appendonly.aof，可以通过appendfilename参数修改 
appendfilename appendonly.aof
```

#### 3.2 AOF 流程及加载数据原理

##### 3.2.1 AOF 原理流程图

![image-20220106112708598](images/image-20220106112708598.png)

其流程图主要分为三个阶段：

- **命令传播**

  当 Client端 将命令发送到 Redis 后，将协议文本的 **字符串转为 Redis的StringObject对象**，并调用函数执行命令，若是写操作则将执行后的命令、参数和参数个数**传播到 AOF 模块**

- **缓存追加**

  AOF 模块接受到数据后，将 **StringObject对象 重新转为协议文本（RESP）**并追加到 **`redis.h/redisServer`（该文件记录了Redis服务端的状态）** 结构的 **`aof_buf`（记录待写入AOF文件的RESP命令）** 末尾

- **写入文件**

  调用 **`aof.c/flushAppendOnlyFile`** 函数，其执行以下两个工作：

  - **WRITE：**根据条件，将 **`aof_buf`** 中的缓存写入到 AOF 文件对象中
  - **SAVE：**根据条件，调用 **`fsync`** 或 **`fdatasync`** 函数，将 AOF 文件保存到磁盘中

##### 3.2.2 AOF 加载数据原理

由于**AOF文件存储的是命令**，而Redis命令**只能在客户端中执行**，所以当Redis重启时，Redis Server会**创建一个不带网络连接的伪客户端**（fake client，**命令来源于AOF文件而不需要网络接收**），通过fake client来执行AOF文件命令来恢复数据

![image-20220107113207836](images/image-20220107113207836.png)

#### 3.3 AOF 触发及保存方式

AOF 目前包含有以下三种保存方式：

![image-20220106153339948](images/image-20220106153339948.png)

- **AOF_FSYNC_NO**

  不保存，每次调用 `flushAppendOnlyFile `函数，只执行`WRITE ` 而不执行`SAVE `。

  但在以下三种情况会执行 `SAVE`（**会阻塞主进程**）：

  - Redis 被关闭

  - AOF 功能被关闭

  - 系统的写缓存被刷新（缓存被写满，定期刷盘从而执行 `SAVE`）

- **AOF_FSYNC_EVERYSEC（默认）**

  每一秒钟保存一次， 此模式的 `SAVE `由后台子进程（fork）调用的， 所以它**不会阻塞主进程**

- **AOF_FSYNC_ALWAYS**

  每执行一个命令保存一次（不推荐），此模式的 `SAVE `由 Redis 主进程执行。每次执行完一个命令之后， `WRITE `和 `SAVE `都会**阻塞主进程**

#### 3.4 AOF 重写/优化

AOF 记录的是操作命令**即所有数据的变化过程**，所以体积会越来越大，Redis提供了重写的机制来为 AOF 文件瘦身，**通过 fork子进程对 AOF进行重写，然后替换旧 AOF 文件**，其重写效果如下：

![image-20220106163551797](images/image-20220106163551797.png)

##### 3.4.1 重写流程

在整个 AOF重写 过程中，只有**主进程for子进程**、主进程**接收子进程信号**并执行**追加缓存**和**替换旧AOF文件** 是**阻塞的**，其他时候都是非阻塞的。这将 AOF 重写对性能造成的影响降到了最低。以下是 AOF后台重写，也即是 **bgrewriteaof** 命令(AOF重写)的工作原理。

![image-20220106170958715](images/image-20220106170958715.png)

**当触发AOF重写机制时，主进程的操作：**

- 主进程会 **fork一个子进程**（同RDB机制一样，调用OS的fork函数克隆一个子进程，**子进程拥有主进程fork时的所有资源**）
- 主进程**继续 AOF 的流程（命令传播、缓存追加、文件写入），将命令写入现有 AOF 文件**（总不能因为AOF重写就不进行最新数据的持久化吧哈哈）
- 主进程将协议文本（RESP）**写入到 AOF缓存文件 的同时**，也会**记录到 AOF重写缓存**（AOF 机制添加了一个 AOF 重写缓存，**用于记录重写过程中主进程接受的新命令**）

**当触发AOF重写机制时，子进程的操作：**

- 子进程 fork自 主进程，拥有主进程相同的内存数据
- 子进程通过对 **AOF缓存文件 + AOF重写缓存 进行优化**，生成瘦身后的 AOF文件
- 子进程完成 AOF重写后，向父进程发送一个完成信号，父进程在接到完成信号之后，会调用一个信号处理函数， 并完成以下工作：
  - 主进程**将 AOF重写缓存 中新添加的数据全部写入到新 AOF 文件中**
  - 对**新的 AOF文件进行改名**，**覆盖**原有的 AOF 文件
  - 这个信号处理函数执行完毕之后， 主进程就可以继续像往常一样接受命令请求了

##### 3.4.2 AOF 重写触发方式

- 配置 `redis.conf` AOF重写规则

  ```sh
  # 表示当前aof文件大小超过上一次aof文件大小的百分之多少的时候会进行重写。如果之前没有重写过， 以启动时aof文件大小为准
  auto-aof-rewrite-percentage 100
  
  # 限制允许重写最小aof文件大小，也就是文件大小小于64mb的时候，不需要进行优化
  auto-aof-rewrite-min-size 64mb
  ```

- 执行bgrewriteaof命令

  ```sh
  127.0.0.1:6379> bgrewriteaof 
  Background append only file rewriting started
  ```





### 4. 混合持久化

Redis4.0 开始支持RDB和AOF混合持久化方式，aofrewrite 的时候就直接把 rdb 的内容写到 aof 文件开头即：**RDB的头+AOF的身体——》appendonly.aof**

#### 4.1 Redis重启时，加载方式

- 首先读取 AOF文件 appendonly.aof
- 判断是否REDIS字符串开头，是则先按RDB格式加载数据
- 再按AOF格式加载剩余数据

#### 4.2 redis.conf 开启配置：

```sh
aof-use-rdb-preamble yes
```





### 5. RDB与AOF 的对比

- RDB存储的是某时刻的**二进制快照数据文件**；而AOF存储的是**协议文本命令**
- RDB持久化的性能较AOF高，**直接通过fork子进程来对数据进行快照**；而AOF主进程需要进行命令传播/缓存追加/写入文件操作（**只有在`EVERYSEC模式`下才会fork子进程来 `SAVE`**），阻塞时间较RDB久。
- RDB持久化按默认触发规则，可能会丢失十几分钟的数据，而AOF至多只会丢失一秒的数据





### 6. 应用场景

#### 6.1 追求高性能

不使用持久化，通过原始数据源，Redis每次启动时都从原始数据源加载数据

#### 6.2 确保数据不易丢失

使用RDB + AOF

#### 6.3 较高性能

使用RDB







## 二、Redis 底层数据结构

![image-20220107161609024](images/image-20220107161609024.png)

### 1. RedisDB对象

Redis 中存在数据库的概念，该**结构由 `redis.h` 中的 RedisDb定义**，保存在**redisServer.db 数组中（RedisServer的一个成员 属性）**，redisClient通过一个名叫db的指针指向当前使用的数据库

**RedisDB 结构体源码如下**

![image-20220107155605682](images/image-20220107155605682.png)

**dict类型**为一个字典，是Redis的一个底层数据结构，key就是需要存储数据的key，详细结构见[叠层结构-hash表](#3.3 hash表)





### 2. RedisObject 对象

value 是一个对象，类型是 RedisObject，其结构源码如下

![image-20220107160323091](images/image-20220107160323091.png)

- **type**

  代表 value对象的**[数据类型](./Redis基础篇/#四、Redis 数据类型)**，常见的有**string(字符串)**、**list(列表)**、**hash(哈希)**、**set(集合)**、**zset(有序集合)等。。。**

  通过命令 **`type key`** 查询 key 对应 value的数据类型

  ```sh
  127.0.0.1:6379> type a1 
  string
  ```

- **encoding**

  代表 value对象的**内部编码**，Redis可通过不同的场景来为对象设置合适的编码，如`set a1 1`，则编码将设置为 int类型，而不是String类型

  通过 **`object encoding key`** ，查询 value 的编码方式

  ```sh
  127.0.0.1:6379> object encoding a1 
  "int"
  ```

- **ptr**

  代表 value对象使用的**[底层的数据结构](#3. 底层数据数据结构)**，ptr指针 指向具体的数据结构，有**SDS**、**skiplist**、**dict/hash**、**quiklist**、**stream**等。。。

- **refcount**

  代表 value对象**被引用的次数**，当refcount > 1 时，被称为共享对象，节省了重复创建相同对象的开销

- **lru**

  代表 value对象最后一次被访问的时间，由24位二进制码组成，高16位存**最近访问时间**，剩余位存储**最近访问次数**

  lru——》 高16位: 最后被访问的时间

  lfu——》低8位：最近访问次数





### 3. 底层数据数据结构

#### 3.1 简单动态字符串SDS

Redis的字符串对象是自己实现的简单动态字符串（Simple Dynamic String）

![image-20220107164653602](images/image-20220107164653602.png)

##### 3.1.1 其结构源码如下

![image-20220107164722277](images/image-20220107164722277.png)

##### 3.1.2 优势如下

- SDS**获取字符串长度的时间复杂度为$O(1)$，**而C语言的字符串为$O(n)$

  $SDS长度 =  free + len + 1$

- 当SDS增加字符时，缓冲区不够存储则会自动分配内存，**防止了缓冲区内存溢出**

##### 3.1.3 使用场景

- 存储key
- 存储value的字符串和整型数据
- AOF缓冲区和用户输入缓冲。

#### 3.2 跳跃表skiplist

**其底层通过有序单向链表 + 分层（多级索引）实现**，最底层包含所有结点，**每隔一个结点向上分一层**，最顶层为两个结点为止，查找类似于二分查找法

若要查找9，只需进行4次查找，示意图如下：

![image-20220107165906793](images/image-20220107165906793.png)

优先**从最高层的第一个结点开始向后查找**，如果**next节点值大于目标值或next指针指向null**，则从当前节点**下降一层继续向后查找**，直到查找到目标值或者null

##### 3.2.1 结构源码如下

![image-20220107171017722](images/image-20220107171017722.png)

跳跃表的特点是 每层都是一个链表

##### 3.2.2 优势如下

- 可以快速查找到需要的结点 $O(log_2n)$
- 可以在$O(1)$的时间复杂度下，**快速获得跳跃表的头节点、尾结点、长度和高度**

##### 3.2.3 使用场景

跳跃表是有序集合（sorted-set）的底层实现，效率高，实现简单

#### 3.3 dict字典（hash表）

dict（字典）的内部维护了一个Hash表（dictht）和字典类型，类图及示意图如下所示

![image-20220108215033996](images/image-20220108215033996.png)

![image-20220108220211187](images/image-20220108220211187.png)

- **dictht：**即hash表，数组的初始容量为4，扩容是时为一倍扩容
- **dictEntry：**即hash表的结点
- **dictType：**type字段，指向dictType结构体，里边包括了对该字典操作的函数指针

##### 3.3.1 结构源码如下

- dict 字典

  ![image-20220108215624505](images/image-20220108215624505.png)

- dictht（hash表）

  ![image-20220108215418258](images/image-20220108215418258.png)

- dictEntry（hash表节点）

  ![image-20220108215445389](images/image-20220108215445389.png)

- dictType

  ![image-20220108220433310](images/image-20220108220433310.png)

##### 3.3.2 dict（字典）的扩容

1. 初次申请默认容量为4个dictEntry，非初次申请为当前hash表容量的一倍。

2. rehashidx=0表示要进行rehash操作。

3. 新增加的数据在新的hash表h[1]

4. 修改、删除、查询在老hash表h[0]、新hash表h[1]中（rehash中）

5. 将老的hash表h[0]的数据重新计算索引值后全部迁移到新的hash表h[1]中，这个过程称为rehash。

##### 3.3.3 使用场景

- k-v存储的hash数据类型
- 所有的散列表对象
- 元素大小过大的集合数据类型（set）
- 哨兵模式中的主从节点管理



#### 3.4 快速列表quiklist

##### 3.4.1 压缩列表ziplist

压缩列表是由一系列**特殊编码的顺序表**组成，示意图如下

![image-20220108235947147](images/image-20220108235947147.png)

结构源码如下

![image-20220109000754771](images/image-20220109000754771.png)

使用场景

- sorted-set和hash元素个数少且是小整数或短字符串（直接使用）
- list用快速链表(quicklist)数据结构存储，而快速链表是双向列表与压缩列表的组合。（间接使用）

##### 3.4.2 整数集合intset

整数集合是一个**有序的**、**存储整数的**、**不会出现重复元素**的**顺序表**，当 集合（set） 是整数并且都处在64位有符号整数范围内（2^64），使用该结构体存储

![image-20220109001324918](images/image-20220109001324918.png)

示意图如下

![image-20220109001753206](images/image-20220109001753206.png)

结构源码

![image-20220109001810536](images/image-20220109001810536.png)

使用场景

- 当集合（set）的元素是整数且大小范围在64位整数内，底层结构使用整数集合

#### 3.5 流对象









## 三、Redis 缓存过期及淘汰策略

maxmemery

删除策略



## 四、Redis 通讯协议及时间处理机制

Redis 请求协议及命令处理流程

Redis 多路复用模式以及实现方式

Redis 时间事件处理机制、文件事件处理机制

![image-20211227153504075](images/image-20211227153504075.png)
